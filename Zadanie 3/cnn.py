# -*- coding: utf-8 -*-
"""I-SUNS: Zadanie 3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hEgyqn-92CCR89dfsM13OfdWpw0OossZ
"""

import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import tensorflow as tf
import pathlib

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

data_dir = pathlib.Path('drive/MyDrive/suns-zadanie3-res/train/')
image_count = len(list(data_dir.glob('**/*.jpg')))
print(image_count)

pho = list(data_dir.glob('pho/*'))
PIL.Image.open(str(pho[42]))

batch_size = 42
img_height = 64
img_width = 64

train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.25,
  subset="training",
  seed=11600,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.3,
  subset="validation",
  seed=255,
  image_size=(img_height, img_width),
  batch_size=batch_size)

class_names = train_ds.class_names
print(class_names)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

bs = None
for image_batch, labels_batch in train_ds:
  bs = image_batch.shape
  print(image_batch.shape)
  print(labels_batch.shape)
  break

num_classes = len(class_names)

model = Sequential([
  layers.RandomTranslation(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2), fill_mode="nearest"),
  layers.RandomFlip(mode="horizontal"),
  layers.RandomRotation(factor=0.15, fill_mode="nearest"),
  layers.RandomZoom(height_factor=(-0.3, 0.1), width_factor=(-0.3, 0.1), fill_mode="nearest"),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu',
                kernel_regularizer =tf.keras.regularizers.l1( l=0.02)
                ),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu',
                kernel_regularizer =tf.keras.regularizers.l2( l=0.04)
                ),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])

checkpoint_path = 'drive/MyDrive/suns-zadanie3-res/reg2/cp.ckpt'
load_checkpoint = False
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

if load_checkpoint:
  # Load the previously saved weights
  latest = pathlib.Path(checkpoint_path)
  model.load_weights(latest)
  model.build(bs)
else:
  AUTOTUNE = tf.data.AUTOTUNE
  train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
  val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

  normalization_layer = layers.Rescaling(1./255)
  # normalizacia (potrebujem aby hodnoty farebnych kanalov boli v intervale [0-1])
  normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
  image_batch, labels_batch = next(iter(normalized_ds))

  # compile
  model.build(bs)
  model.summary()

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

# definujeme callbacky do tensorboardu
import datetime
log_dir = "logs/zad3/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

if not load_checkpoint:
  tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)

  # calbacky
  checkpoint_dir = os.path.dirname(checkpoint_path)

  # Create a callback that saves the model's weights
  cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                  save_weights_only=True,
                                                  verbose=1)
  import datetime
  epochs=80

  history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=epochs,
    callbacks=[tensorboard_callback, cp_callback]
  )
  model.save_weights('drive/MyDrive/suns-zadanie3-res/reg2/weights.h5')

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

from matplotlib import pyplot
conv_layers = []
for layer in model.layers:
  if 'conv' not in layer.name:
    continue
  conv_layers.append(layer)
for cl in conv_layers:
  filters, biases = cl.get_weights()
  f_min, f_max = filters.min(), filters.max()
  filters = (filters - f_min) / (f_max - f_min)
  n_filters, ix = 6, 1
  for i in range(n_filters):
    f = filters[:, :, :, i]
    for j in range(3):
      ax = pyplot.subplot(n_filters, 3, ix)
      ax.set_xticks([])
      ax.set_yticks([])
      pyplot.imshow(f[:, :, j])
      ix += 1
  pyplot.show()

data_dir_test = pathlib.Path('drive/MyDrive/suns-zadanie3-res/test/')

test_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir_test,
  image_size=(img_height, img_width),
  batch_size=batch_size)

from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
datagen = ImageDataGenerator(rescale=1. / 255) 

generator_top = datagen.flow_from_directory( 
   data_dir_test, 
   target_size=(img_width, img_height), 
   batch_size=batch_size, 
   class_mode='categorical', 
   shuffle=False)

y_pred = model.predict(test_ds)
test_label = np.concatenate([y for x, y in test_ds], axis=0)

from sklearn import metrics
y_pred = np.argmax(y_pred, axis=1)

cm = metrics.confusion_matrix(test_label, y_pred)

test_loss, test_acc = model.evaluate(test_ds,verbose=2)

print('\nTest accuracy:', test_acc)

import itertools

plt.figure(figsize=(15,15))
plt.imshow(cm, interpolation='nearest', cmap=pyplot.cm.Blues)
plt.title('Confusion matrix')
plt.colorbar()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names, rotation=90)
plt.yticks(tick_marks, class_names)
 

normalize = False
fmt = '.2f' if normalize else 'd'
thresh = cm.max() / 2.
for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
  plt.text(j, i, format(cm[i, j], fmt), horizontalalignment='center', color='white' if cm[i, j] > thresh else 'black')
 
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')

# !tensorboard dev upload \
#   --logdir logs \
#   --name "I-SUNS: Zadanie 3"

data_augmentation = tf.keras.Sequential([
  layers.RandomTranslation(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2), fill_mode="nearest"),
  layers.RandomFlip(mode="horizontal"),
  layers.RandomRotation(factor=0.15, fill_mode="nearest"),
  layers.RandomZoom(height_factor=(-0.3, 0.1), width_factor=(-0.3, 0.1), fill_mode="nearest"),
])

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(3):
    image = images[i]

for i in range(9):
  image = data_augmentation(image)
  ax = plt.subplot(3, 3, i + 1)
  plt.imshow(image.numpy().astype("uint8"))
  plt.axis("off")

